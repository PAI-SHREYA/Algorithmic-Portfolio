{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hx4RaV66OraL"
      },
      "outputs": [],
      "source": [
        "############################################# final code #########################\n",
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models import Word2Vec\n",
        "import random\n",
        "import matplotlib.patches as mpatches\n",
        "from heapq import heappush, heappop\n",
        "\n",
        "# Create a OneHotEncoder instance\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "csv_file = \"amazon.csv\"\n",
        "\n",
        "# Read the CSV data and create a dictionary of products\n",
        "products_dict = {}\n",
        "with open(csv_file, mode='r', encoding='utf-8') as file:\n",
        "    csv_reader = csv.DictReader(file)\n",
        "    for row in csv_reader:\n",
        "        # Extract and clean the rating_count\n",
        "        try:\n",
        "            rating_count = int(row['rating_count'].replace(',', '')) if row['rating_count'] else 0\n",
        "        except ValueError:\n",
        "            rating_count = 0\n",
        "\n",
        "        # Extract and clean the rating\n",
        "        try:\n",
        "            rating = float(row['rating'])\n",
        "        except ValueError:\n",
        "            rating = 0.0\n",
        "\n",
        "        # Create a dictionary for each product\n",
        "        product_details = {\n",
        "            'product_id': row['product_id'],\n",
        "            'product_name': row['product_name'],\n",
        "            'category': row['category'],\n",
        "            'rating': rating,\n",
        "            'rating_count': rating_count,\n",
        "            'about_product': row['about_product']\n",
        "        }\n",
        "        # Use product_id as the key for the products dictionary\n",
        "        products_dict[row['product_id']] = product_details\n",
        "\n",
        "# Print available product IDs\n",
        "print(\"Available product IDs:\", list(products_dict.keys())[:10])  # Print first 10 product IDs for checking\n",
        "\n",
        "# Construct the grid\n",
        "num_products = len(products_dict)\n",
        "grid_size = int(np.ceil(np.sqrt(num_products)))\n",
        "grid = np.empty((grid_size, grid_size), dtype=object)\n",
        "\n",
        "# Calculate row indices using hybrid filtering\n",
        "categories = np.array([p['category'] for p in products_dict.values()]).reshape(-1, 1)\n",
        "category_encoded = encoder.fit_transform(categories)\n",
        "\n",
        "# Use np.log1p for rating_count to handle skewness\n",
        "features = np.array([[p['rating'], np.log1p(p['rating_count'])] for p in products_dict.values()])\n",
        "scaler = MinMaxScaler()\n",
        "normalized_features = scaler.fit_transform(features)\n",
        "normalized_row_indices = normalized_features[:, 0]\n",
        "\n",
        "# Combine the category encoding with the normalized features\n",
        "combined_features = np.concatenate((category_encoded, normalized_features), axis=1)\n",
        "\n",
        "# Debug print to check the feature values before and after normalization\n",
        "print(\"Combined Features (before scaling):\\n\", features[:10])  # Print first 10 for checking\n",
        "print(\"Normalized Features (after scaling):\\n\", normalized_features[:10])  # Print first 10 for checking\n",
        "\n",
        "# Calculate column indices using Word2Vec embeddings for better semantic similarity\n",
        "corpus = [p['about_product'].split() for p in products_dict.values()]\n",
        "word2vec_model = Word2Vec(sentences=corpus, vector_size=50, window=5, min_count=1, workers=4)\n",
        "product_vectors = np.array([np.mean([word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
        "                                    or [np.zeros(50)], axis=0) for words in corpus])\n",
        "\n",
        "column_indices = scaler.fit_transform(product_vectors)\n",
        "\n",
        "# Normalize indices to fit within grid size\n",
        "normalized_col_indices = column_indices[:, 0]\n",
        "row_indices = (normalized_row_indices * (grid_size - 1)).astype(int)\n",
        "column_indices = (normalized_col_indices * (grid_size - 1)).astype(int)\n",
        "\n",
        "# Shuffle the product IDs to ensure a random distribution\n",
        "product_ids = list(products_dict.keys())\n",
        "random.shuffle(product_ids)\n",
        "\n",
        "# Place products in the grid based on normalized indices\n",
        "for idx, product_id in enumerate(product_ids):\n",
        "    row = row_indices[idx]\n",
        "    col = column_indices[idx]\n",
        "    while grid[row, col] is not None:\n",
        "        col = (col + 1) % grid_size\n",
        "        if col == 0:\n",
        "            row = (row + 1) % grid_size\n",
        "    grid[row, col] = product_id\n",
        "    # print(f\"Product ID: {product_id}, Normalized Row: {normalized_row_indices[idx]:.2f}, Normalized Column: {normalized_col_indices[idx]:.2f}\")\n",
        "\n",
        "def a_star_search_recommendations(start, destination, grid, products_dict, max_recommendations=10):\n",
        "    def heuristic(product1, product2):\n",
        "        # Calculate the grid distance (Manhattan distance)\n",
        "        grid_distance = abs(product1[0] - product2[0]) + abs(product1[1] - product2[1])\n",
        "        # Calculate the product similarity using BERT embeddings\n",
        "        product_similarity = calculate_similarity(products_dict[grid[product1[0], product1[1]]], products_dict[grid[product2[0], product2[1]]])\n",
        "        # Combine the grid distance and product similarity\n",
        "        return grid_distance - product_similarity\n",
        "\n",
        "    def get_neighbors(row, col):\n",
        "        neighbors = []\n",
        "        if row > 0: neighbors.append((row - 1, col))\n",
        "        if row < grid_size - 1: neighbors.append((row + 1, col))\n",
        "        if col > 0: neighbors.append((row, col - 1))\n",
        "        if col < grid_size - 1: neighbors.append((row, col + 1))\n",
        "        return neighbors\n",
        "\n",
        "    start_position = None\n",
        "    destination_position = None\n",
        "    for i in range(grid_size):\n",
        "        for j in range(grid_size):\n",
        "            if grid[i, j] == start:\n",
        "                start_position = (i, j)\n",
        "            if grid[i, j] == destination:\n",
        "                destination_position = (i, j)\n",
        "            if start_position and destination_position:\n",
        "                break\n",
        "        if start_position and destination_position:\n",
        "            break\n",
        "\n",
        "    open_set = []\n",
        "    heappush(open_set, (0, start_position))\n",
        "    came_from = {}\n",
        "    g_score = {pos: float('inf') for row in range(grid_size) for pos in [(row, col) for col in range(grid_size)]}\n",
        "    g_score[start_position] = 0\n",
        "    f_score = {pos: float('inf') for row in range(grid_size) for pos in [(row, col) for col in range(grid_size)]}\n",
        "    f_score[start_position] = heuristic(start_position, destination_position)\n",
        "\n",
        "    path = []\n",
        "    while open_set:\n",
        "        _, current = heappop(open_set)\n",
        "        if current == destination_position:\n",
        "            # Reconstruct the path\n",
        "            while current in came_from:\n",
        "                path.append(current)\n",
        "                current = came_from[current]\n",
        "            path.append(start_position)\n",
        "            path.reverse()\n",
        "            break\n",
        "\n",
        "        neighbors = get_neighbors(current[0], current[1])\n",
        "        for neighbor in neighbors:\n",
        "            neighbor_product = grid[neighbor[0], neighbor[1]]\n",
        "            if neighbor_product:\n",
        "                tentative_g_score = g_score[current] + calculate_similarity(products_dict[grid[current[0], current[1]]], products_dict[neighbor_product])\n",
        "                if tentative_g_score < g_score[neighbor]:\n",
        "                    came_from[neighbor] = current\n",
        "                    g_score[neighbor] = tentative_g_score\n",
        "                    f_score[neighbor] = g_score[neighbor] + heuristic(neighbor, destination_position)\n",
        "                    heappush(open_set, (f_score[neighbor], neighbor))\n",
        "\n",
        "    recommendations = [grid[row, col] for row, col in path]\n",
        "    return recommendations, path\n",
        "\n",
        "# Choose valid start and destination product IDs from the printed list\n",
        "start_product_id = \"B09CQGV36R\"  # Use an available product ID from the list\n",
        "destination_product_id = \"B00E5WECYE\"  # Use another available product ID from the list\n",
        "\n",
        "recommendations, path = a_star_search_recommendations(start_product_id, destination_product_id, grid, products_dict, max_recommendations=10)\n",
        "print(\"Recommended products:\", recommendations)\n",
        "\n",
        "# Visualization with A* path\n",
        "plt.figure(figsize=(20, 20))  # Adjusted figure size\n",
        "\n",
        "# Define colors for categories\n",
        "categories_unique = list(set(p['category'] for p in products_dict.values()))\n",
        "category_colors = {category: plt.cm.tab20(i / len(categories_unique)) for i, category in enumerate(categories_unique)}\n",
        "\n",
        "# Plot the grid cells with category colors\n",
        "for (row, col), product_id in np.ndenumerate(grid):\n",
        "    if product_id is not None:\n",
        "        product = products_dict[product_id]\n",
        "        color = category_colors[product['category']]\n",
        "        plt.scatter(col, row, color=color, marker='s')\n",
        "\n",
        "# Highlight the recommended products\n",
        "for product_id in recommendations:\n",
        "    for i in range(grid_size):\n",
        "        for j in range(grid_size):\n",
        "            if grid[i, j] == product_id:\n",
        "                product = products_dict[product_id]\n",
        "                color = category_colors[product['category']]\n",
        "                plt.scatter(j, i, color=color, marker='o', s=100)\n",
        "\n",
        "# Highlight the A* path\n",
        "path_x = [col for row, col in path]\n",
        "path_y = [row for row, col in path]\n",
        "plt.plot(path_x, path_y, 'ro-', linewidth=2)  # Highlight the path with red lines\n",
        "\n",
        "# Create a legend with category colors\n",
        "handles = [mpatches.Patch(color=color, label=category) for category, color in category_colors.items()]\n",
        "plt.legend(handles=handles, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
        "\n",
        "plt.xlabel('Embedding-based Column Index')\n",
        "plt.ylabel('Hybrid Filtering-based Row Index')\n",
        "plt.axis('off')  # Turn off the axis\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Recommended Products:\")\n",
        "for idx, product_id in enumerate(recommendations, 1):\n",
        "    product = products_dict[product_id]\n",
        "    print(f\"{idx}. Product ID: {product_id}\")\n",
        "    print(f\"   Product Name: {product['product_name']}\")\n",
        "    print(f\"   Category: {product['category']}\")\n",
        "    print(f\"   Rating: {product['rating']}\")\n",
        "    print(f\"   Rating Count: {product['rating_count']}\")\n",
        "    print(f\"   Description: {product['about_product']}\")\n",
        "    print(\"\")"
      ],
      "metadata": {
        "id": "o6XBzKL0Oz5J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}